import OpenAI from "openai";
import { Scenario, Persona } from "./types";
import { constructSystemPrompt } from "./prompts";
import { CardData } from "./card-types";
import { AGENT_TOOLS, AGENT_SYSTEM_PROMPT, ToolCall, QuickReply } from "./agent";

// åˆå§‹åŒ–å®¢æˆ·ç«¯
const apiKey = process.env.NEXT_PUBLIC_DEEPSEEK_API_KEY;

export const deepseek = new OpenAI({
    baseURL: "https://api.deepseek.com",
    apiKey: apiKey || "sk-placeholder",
    dangerouslyAllowBrowser: true
});

export type DeepSeekMessage = OpenAI.Chat.Completions.ChatCompletionMessageParam;

export interface AIResponse {
    content: string;
    cardData?: CardData;
}

// ===== Agent å“åº”ç±»å‹ =====
export interface AgentResponse {
    message: string;
    toolCall?: ToolCall;  // æ”¹ä¸ºå•ä¸ªå·¥å…·è°ƒç”¨
    quickReplies?: QuickReply[];
}

// ===== AI Agent è°ƒç”¨ (æ”¯æŒ Function Calling & Streaming) =====
export async function callAgent(
    messages: DeepSeekMessage[],
    currentWord: string,
    wordMeaning: string,
    onToken?: (token: string) => void
): Promise<AgentResponse> {

    // Dynamic Context Injection (Lightweight)
    const dynamicContext = `
[Context]
Target Word: "${currentWord}" (${wordMeaning})
`;

    try {
        const stream = await deepseek.chat.completions.create({
            messages: [
                { role: "system", content: AGENT_SYSTEM_PROMPT },
                { role: "system", content: dynamicContext },
                ...messages
            ],
            model: "deepseek-chat",
            // ã€é‡è¦ã€‘ä¸ä¼  tools å‚æ•°ï¼Œå®Œå…¨ç¦æ­¢å·¥å…·è°ƒç”¨
            stream: true
        });

        let fullContent = "";
        let toolCallAccumulator: any = null;

        for await (const chunk of stream) {
            const delta = chunk.choices[0]?.delta;
            if (delta?.content) {
                fullContent += delta.content;
                if (onToken) onToken(delta.content);
            }
            if (delta?.tool_calls) {
                if (!toolCallAccumulator) toolCallAccumulator = [];
                for (const tc of delta.tool_calls) {
                    if (!toolCallAccumulator[tc.index]) {
                        toolCallAccumulator[tc.index] = { ...tc, function: { ...tc.function, arguments: "" } };
                    }
                    if (tc.function?.arguments) {
                        toolCallAccumulator[tc.index].function.arguments += tc.function.arguments;
                    }
                    if (tc.function?.name) {
                        toolCallAccumulator[tc.index].function.name = tc.function.name;
                    }
                }
            }
        }

        // åªå–ç¬¬ä¸€ä¸ªå·¥å…·è°ƒç”¨
        let toolCall: ToolCall | undefined;
        if (toolCallAccumulator && toolCallAccumulator.length > 0) {
            const firstTc = toolCallAccumulator[0];
            try {
                toolCall = {
                    name: firstTc.function.name,
                    arguments: JSON.parse(firstTc.function.arguments || "{}")
                };
            } catch (e) {
                console.warn("Failed to parse tool arguments:", e);
            }
        }

        // ä¸å†åœ¨è¿™é‡Œç”Ÿæˆå¿«æ·å›å¤ï¼Œè®© chat-store.ts ä½¿ç”¨ generateContextualReplies ç»Ÿä¸€å¤„ç†
        return {
            message: fullContent,
            toolCall,
            quickReplies: undefined // è®© chat-store ä½¿ç”¨ä¸Šä¸‹æ–‡æ„ŸçŸ¥ç”Ÿæˆå™¨
        };

    } catch (error) {
        console.error("Agent Error:", error);
        return {
            message: "æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›é—®é¢˜ã€‚è¯·å†è¯•ä¸€æ¬¡ã€‚",
            quickReplies: [{ text: "é‡è¯•", emoji: "ğŸ”„" }]
        };
    }
}

// æ ¹æ®å·¥å…·è°ƒç”¨ç”Ÿæˆåˆé€‚çš„å¿«æ·å›å¤
function generateQuickReplies(toolCall?: ToolCall): QuickReply[] {
    if (!toolCall) {
        return [
            { text: "ç»§ç»­", emoji: "ğŸ‘" },
            { text: "è€ƒè€ƒæˆ‘", emoji: "â“" },
        ];
    }

    switch (toolCall.name) {
        case "show_card":
            const cardType = toolCall.arguments?.card_type as string;
            if (cardType === "vocabulary") {
                return [
                    { text: "è®°ä½äº†", emoji: "ğŸ‘" },
                    { text: "æœ‰ç‚¹éš¾", emoji: "ğŸ˜…" },
                ];
            }
            // äº¤äº’å¡ç‰‡ä¸éœ€è¦å¿«æ·å›å¤
            return [];

        case "next_word":
            return [
                { text: "å¼€å§‹å­¦ä¹ ", emoji: "ğŸ“š" },
            ];
    }

    return [
        { text: "ç»§ç»­", emoji: "ğŸ‘" },
    ];
}

// ===== æµå¼ç”Ÿæˆ (Streaming Generation) =====
export async function generateResponseStreaming(
    messages: DeepSeekMessage[],
    scenario: Scenario,
    persona: Persona,
    onDelta: (delta: string) => void,
    onComplete: (response: AIResponse) => void
): Promise<void> {
    const systemPrompt = constructSystemPrompt(scenario, persona);

    try {
        const stream = await deepseek.chat.completions.create({
            messages: [
                { role: "system", content: systemPrompt },
                ...messages
            ],
            model: "deepseek-chat",
            stream: true
        });

        let fullContent = "";

        for await (const chunk of stream) {
            const delta = chunk.choices[0]?.delta?.content || "";
            fullContent += delta;
            onDelta(delta);
        }

        const { content, cardData } = parseCardFromContent(fullContent);
        onComplete({ content, cardData });

    } catch (error) {
        console.error("DeepSeek Streaming Error:", error);
        onComplete({ content: "è¿æ¥å‡ºé”™ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ– API Keyã€‚" });
    }
}

// ===== éæµå¼ç”Ÿæˆ (Non-Streaming) =====
export async function generateResponse(
    messages: DeepSeekMessage[],
    scenario: Scenario,
    _persona: Persona
): Promise<AIResponse> {
    const systemPrompt = scenario.systemPrompt || constructSystemPrompt(scenario, _persona);

    try {
        const completion = await deepseek.chat.completions.create({
            messages: [
                { role: "system", content: systemPrompt },
                ...messages
            ],
            model: "deepseek-chat",
        });

        const rawContent = completion.choices[0].message.content || "";
        return parseCardFromContent(rawContent);

    } catch (error) {
        console.error("DeepSeek API Error:", error);
        return {
            content: "æˆ‘ç°åœ¨æ— æ³•è¿æ¥åˆ°å¤§è„‘ï¼Œè¯·æ£€æŸ¥ API è¿æ¥ã€‚",
        };
    }
}

// ===== Helper: ä»å›å¤ä¸­æå– Card JSON =====
function parseCardFromContent(rawContent: string): AIResponse {
    const jsonMatch = rawContent.match(/```json\s*(\{[\s\S]*?\})\s*```/) || rawContent.match(/\{[\s\S]*\}$/);

    let content = rawContent;
    let cardData: CardData | undefined;

    if (jsonMatch) {
        try {
            const jsonStr = jsonMatch[1] || jsonMatch[0];
            const parsed = JSON.parse(jsonStr);

            if (parsed.card) {
                cardData = parsed.card;
                content = rawContent.replace(jsonMatch[0], "").trim();
            }
        } catch (e) {
            console.warn("Failed to parse AI JSON:", e);
        }
    }

    return { content, cardData };
}

// ===== ç®€å•å¯¹è¯è°ƒç”¨ (Simple Chat) =====
export async function callSimpleChat(
    systemPrompt: string,
    userMessage: string
): Promise<string> {
    try {
        const completion = await deepseek.chat.completions.create({
            messages: [
                { role: "system", content: systemPrompt },
                { role: "user", content: userMessage }
            ],
            model: "deepseek-chat",
            temperature: 0.7
        });

        return completion.choices[0].message.content || "";
    } catch (error) {
        console.error("Simple Chat Error:", error);
        return "Thinking error...";
    }
}

// ===== æ•™å­¦æµå¼å“åº” (ä¸ä½¿ç”¨ toolsï¼Œçº¯æ–‡æœ¬è¾“å‡º) =====
export async function callTeachingStream(
    systemPrompt: string,
    messages: DeepSeekMessage[],
    onToken: (token: string) => void
): Promise<string> {
    try {
        const stream = await deepseek.chat.completions.create({
            messages: [
                { role: "system", content: systemPrompt },
                ...messages
            ],
            model: "deepseek-chat",
            temperature: 0.8,
            stream: true
            // æ³¨æ„ï¼šä¸ä½¿ç”¨ toolsï¼Œç¡®ä¿çº¯æ–‡æœ¬è¾“å‡º
        });

        let fullContent = "";

        for await (const chunk of stream) {
            const delta = chunk.choices[0]?.delta?.content || "";
            fullContent += delta;
            if (delta) onToken(delta);
        }

        return fullContent;

    } catch (error) {
        console.error("Teaching Stream Error:", error);
        return "ï¼ˆæ•™å­¦å†…å®¹åŠ è½½å¤±è´¥ï¼‰";
    }
}
